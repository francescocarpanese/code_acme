{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "mount_file_id": "1ooWz1I4kxMbhMzuZvYeI0jI2NgapFb7M",
      "authorship_tag": "ABX9TyOb7JHokCGOCh5l9ztiUlLb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cisk1990/code-acme/blob/main/trial_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_0BML4llJ4-",
        "outputId": "94423116-65a8-4ba7-bf8b-b33ab9e15665"
      },
      "source": [
        "cd /content/drive/MyDrive\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmomfbZVl-RU",
        "outputId": "d5d020df-75dc-425e-cb24-d0afcecffdf7"
      },
      "source": [
        "!git clone https://github.com/cisk1990/code-acme.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code-acme'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOnqCHoCmFEx",
        "outputId": "5b3f6ce5-a009-4267-ce7b-e1feac95eaa4"
      },
      "source": [
        "!git clone https://github.com/cisk1990/code-acme.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code-acme'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc_RziOrmVP6",
        "outputId": "534e2aac-1f83-466d-de9a-f0b3c62f9cce"
      },
      "source": [
        "!git clone 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/https://github.com/cisk1990/code-acme.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code-acme'...\n",
            "fatal: I don't handle protocol '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/https'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grOgXVKMnxjj",
        "outputId": "a3d25cca-e9c7-477a-ea5e-7f39a32b657a"
      },
      "source": [
        "!git clone https://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@github.com/cisk1990/code-acme.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'code-acme'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 41 (delta 10), reused 37 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9HbWRWGoHSq",
        "outputId": "e1810c41-b45a-44d7-9b80-e1a9f6741566"
      },
      "source": [
        "cd code-acme"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/code-acme\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46dRmVKjoOiA",
        "outputId": "0a8f4c16-2eea-49e5-819a-71ace91089cd"
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dockerfile  \u001b[0m\u001b[01;34menvironments\u001b[0m/  \u001b[01;34mexamples\u001b[0m/  README.md  setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT1KPLDSoSjI",
        "outputId": "ffa69162-05b9-429f-cbdb-926149842103"
      },
      "source": [
        "!docker build -t trial ."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: docker: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dk3xG2CoW8Q",
        "outputId": "ccfb6074-7c12-49a8-da44-045820bbc532"
      },
      "source": [
        "!python -m venv .code-acme"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Command '['/content/drive/My Drive/code-acme/.code-acme/bin/python3', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izq2Walfo3Hz",
        "outputId": "7787570c-b80b-4a4c-be86-46ea8f6cdfaf"
      },
      "source": [
        "!python3 -m pip install --user virtualenv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.10.0-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 12.3 MB/s \n",
            "\u001b[?25hCollecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.3-py2.py3-none-any.whl (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.8.2)\n",
            "Collecting backports.entry-points-selectable>=1.0.4\n",
            "  Downloading backports.entry_points_selectable-1.1.1-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.15.0)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.10.0.2)\n",
            "Installing collected packages: platformdirs, distlib, backports.entry-points-selectable, virtualenv\n",
            "\u001b[33m  WARNING: The script virtualenv is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed backports.entry-points-selectable-1.1.1 distlib-0.3.3 platformdirs-2.4.0 virtualenv-20.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ2QHq0DpAMQ",
        "outputId": "cee66ae5-a474-4b43-f830-bcc1ddb1d715"
      },
      "source": [
        "!python3 -m venv .code-acme"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Command '['/content/drive/My Drive/code-acme/.code-acme/bin/python3', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkDqwxALpD-O",
        "outputId": "1a10aafe-dc6c-4708-e8ec-a556f80baddf"
      },
      "source": [
        "!pip3 install virtualenv\n",
        "!virtualenv .code-acme"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: virtualenv in /root/.local/lib/python3.7/site-packages (20.10.0)\n",
            "Requirement already satisfied: backports.entry-points-selectable>=1.0.4 in /root/.local/lib/python3.7/site-packages (from virtualenv) (1.1.1)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /root/.local/lib/python3.7/site-packages (from virtualenv) (2.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.8.2)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.4.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /root/.local/lib/python3.7/site-packages (from virtualenv) (0.3.3)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.10.0.2)\n",
            "/bin/bash: virtualenv: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f-XOmgxpTO4",
        "outputId": "c43be714-a1de-44ec-ed72-f02c580186c8"
      },
      "source": [
        "!source .code-acme/bin/activate"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: .code-acme/bin/activate: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSDoJg0spaYA",
        "outputId": "0c5896c8-4571-4901-ca7c-8cc734a93c9d"
      },
      "source": [
        "ls\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dockerfile  \u001b[0m\u001b[01;34menvironments\u001b[0m/  \u001b[01;34mexamples\u001b[0m/  README.md  setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpr2pdtxpcUY",
        "outputId": "9f711d31-18c9-4eab-e0e4-3fed77b6cad4"
      },
      "source": [
        "!pip install .[dev]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/My Drive/code-acme\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting pytest-xdist\n",
            "  Downloading pytest_xdist-2.4.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from code-acme==0.0) (4.10.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from code-acme==0.0) (5.5.0)\n",
            "Collecting dm-acme==0.2.2\n",
            "  Downloading dm-acme-0.2.2.tar.gz (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 18.7 MB/s \n",
            "\u001b[?25hCollecting tfp-nightly==0.14.0.dev20210818\n",
            "  Downloading tfp_nightly-0.14.0.dev20210818-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 67.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow_probability==0.14.1\n",
            "  Downloading tensorflow_probability-0.14.1-py2.py3-none-any.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (0.12.0)\n",
            "Collecting dm_env\n",
            "  Downloading dm_env-1.5-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (0.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (7.1.2)\n",
            "Collecting bsuite\n",
            "  Downloading bsuite-0.3.5.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting dm-control\n",
            "  Downloading dm_control-0.0.403778684-py3-none-any.whl (38.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (0.17.3)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (4.0.1)\n",
            "Collecting dm-launchpad-nightly\n",
            "  Downloading dm_launchpad_nightly-0.3.0.dev20211205-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 63.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (0.2.25)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (0.1.71+cuda111)\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.5-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 84.8 MB/s \n",
            "\u001b[?25hCollecting dm-reverb\n",
            "  Downloading dm_reverb-0.6.1-cp37-cp37m-manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 17.7 MB/s \n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 90.2 MB/s \n",
            "\u001b[?25hCollecting rlax\n",
            "  Downloading rlax-0.1.1-py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 90.7 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-acme==0.2.2->code-acme==0.0) (3.10.0.2)\n",
            "Collecting dm-sonnet\n",
            "  Downloading dm_sonnet-2.0.0-py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 85.4 MB/s \n",
            "\u001b[?25hCollecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.14.1->code-acme==0.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.14.1->code-acme==0.0) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.14.1->code-acme==0.0) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.14.1->code-acme==0.0) (0.4.0)\n",
            "Collecting frozendict\n",
            "  Downloading frozendict-2.1.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bsuite->dm-acme==0.2.2->code-acme==0.0) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from bsuite->dm-acme==0.2.2->code-acme==0.0) (1.1.5)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (from bsuite->dm-acme==0.2.2->code-acme==0.0) (0.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bsuite->dm-acme==0.2.2->code-acme==0.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from bsuite->dm-acme==0.2.2->code-acme==0.0) (0.18.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from bsuite->dm-acme==0.2.2->code-acme==0.0) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (2.23.0)\n",
            "Collecting glfw\n",
            "  Downloading glfw-2.4.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 64.9 MB/s \n",
            "\u001b[?25hCollecting labmaze\n",
            "  Downloading labmaze-1.0.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (4.62.3)\n",
            "Requirement already satisfied: pyopengl>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (3.1.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (4.2.6)\n",
            "Requirement already satisfied: protobuf>=3.15.6 in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (3.17.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (3.0.6)\n",
            "Requirement already satisfied: setuptools!=50.0.0 in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (57.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from dm-control->dm-acme==0.2.2->code-acme==0.0) (3.1.0)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku->dm-acme==0.2.2->code-acme==0.0) (0.8.9)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.7/dist-packages (from dm-launchpad-nightly->dm-acme==0.2.2->code-acme==0.0) (1.42.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from dm-launchpad-nightly->dm-acme==0.2.2->code-acme==0.0) (5.4.8)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from dm-launchpad-nightly->dm-acme==0.2.2->code-acme==0.0) (1.3.9)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->dm-acme==0.2.2->code-acme==0.0) (1.13.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->dm-acme==0.2.2->code-acme==0.0) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->dm-acme==0.2.2->code-acme==0.0) (0.2.9)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym->dm-acme==0.2.2->code-acme==0.0) (4.1.2.30)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->dm-control->dm-acme==0.2.2->code-acme==0.0) (1.5.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->code-acme==0.0) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->code-acme==0.0) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->code-acme==0.0) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->code-acme==0.0) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->code-acme==0.0) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->code-acme==0.0) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->code-acme==0.0) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->code-acme==0.0) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->code-acme==0.0) (0.2.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->dm-acme==0.2.2->code-acme==0.0) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib->dm-acme==0.2.2->code-acme==0.0) (2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->code-acme==0.0) (4.9.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->code-acme==0.0) (22.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->code-acme==0.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite->dm-acme==0.2.2->code-acme==0.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite->dm-acme==0.2.2->code-acme==0.0) (1.3.2)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->dm-acme==0.2.2->code-acme==0.0) (0.11.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->bsuite->dm-acme==0.2.2->code-acme==0.0) (2018.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->code-acme==0.0) (0.7.0)\n",
            "Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite->dm-acme==0.2.2->code-acme==0.0) (1.1.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite->dm-acme==0.2.2->code-acme==0.0) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite->dm-acme==0.2.2->code-acme==0.0) (0.5.2)\n",
            "Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite->dm-acme==0.2.2->code-acme==0.0) (0.6.0)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine->bsuite->dm-acme==0.2.2->code-acme==0.0) (3.3.0)\n",
            "Collecting pytest-forked\n",
            "  Downloading pytest_forked-1.3.0-py2.py3-none-any.whl (4.7 kB)\n",
            "Collecting pytest>=6.0.0\n",
            "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 69.4 MB/s \n",
            "\u001b[?25hCollecting execnet>=1.1\n",
            "  Downloading execnet-1.9.0-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.0->pytest-xdist->code-acme==0.0) (0.10.2)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.0->pytest-xdist->code-acme==0.0) (21.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.0->pytest-xdist->code-acme==0.0) (1.1.1)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.0->pytest-xdist->code-acme==0.0) (1.11.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.0->pytest-xdist->code-acme==0.0) (21.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.0->pytest-xdist->code-acme==0.0) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=6.0.0->pytest-xdist->code-acme==0.0) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->dm-control->dm-acme==0.2.2->code-acme==0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->dm-control->dm-acme==0.2.2->code-acme==0.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->dm-control->dm-acme==0.2.2->code-acme==0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->dm-control->dm-acme==0.2.2->code-acme==0.0) (2.10)\n",
            "Collecting jax\n",
            "  Downloading jax-0.2.21.tar.gz (756 kB)\n",
            "\u001b[K     |████████████████████████████████| 756 kB 32.7 MB/s \n",
            "\u001b[?25hCollecting distrax>=0.0.2\n",
            "  Downloading distrax-0.1.0-py3-none-any.whl (221 kB)\n",
            "\u001b[K     |████████████████████████████████| 221 kB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite->dm-acme==0.2.2->code-acme==0.0) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite->dm-acme==0.2.2->code-acme==0.0) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite->dm-acme==0.2.2->code-acme==0.0) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite->dm-acme==0.2.2->code-acme==0.0) (2021.11.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (12.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (0.22.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (0.37.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (2.7.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->dm-acme==0.2.2->code-acme==0.0) (2.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->dm-acme==0.2.2->code-acme==0.0) (3.1.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->dm-acme==0.2.2->code-acme==0.0) (0.3.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->dm-acme==0.2.2->code-acme==0.0) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->dm-acme==0.2.2->code-acme==0.0) (1.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->dm-acme==0.2.2->code-acme==0.0) (5.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets->dm-acme==0.2.2->code-acme==0.0) (1.53.0)\n",
            "Building wheels for collected packages: code-acme, dm-acme, bsuite, jax\n",
            "  Building wheel for code-acme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for code-acme: filename=code_acme-0.0-py3-none-any.whl size=4953 sha256=0112ff1d40ebbd2db4fc05b29f992e5a2200b144fa4708e8039e5a33f7d19e3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/6e/e3/a02ef137b2ad8285b7368323d22b8ae55fd26e632e423ab386\n",
            "  Building wheel for dm-acme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-acme: filename=dm_acme-0.2.2-py3-none-any.whl size=436180 sha256=4e4c70f121140e50aaf20b73c09078352c3f130018b00085a2698b1ad819b01a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/6f/c4/d10474b87edcfdfc57efa1a3c0edaa1fbe59c14e98699e4a45\n",
            "  Building wheel for bsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bsuite: filename=bsuite-0.3.5-py3-none-any.whl size=245535 sha256=3e6701dfb486cd3e0ebf7a70335e1f965ddcf30052f4e201f66c65d981879552\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/b5/ca/0c07a074948945a11237574bf3f3aab72cac029e2eebd38dac\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.2.21-py3-none-any.whl size=869303 sha256=e73fd1e71f95f92b23c20f838eebe7968e658e52cba2152d03109af8515364c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/69/0d/3784dd6d281be0837d8cef1db0c8b37d108c8bff727b961178\n",
            "Successfully built code-acme dm-acme bsuite jax\n",
            "Installing collected packages: jax, tensorflow-probability, pluggy, chex, pytest, mock, labmaze, jmp, glfw, frozendict, dm-env, distrax, trfl, tfp-nightly, rlax, pytest-forked, optax, execnet, dm-sonnet, dm-reverb, dm-launchpad-nightly, dm-haiku, dm-control, dm-acme, dataclasses, bsuite, pytest-xdist, code-acme\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.2.25\n",
            "    Uninstalling jax-0.2.25:\n",
            "      Successfully uninstalled jax-0.2.25\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.15.0\n",
            "    Uninstalling tensorflow-probability-0.15.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.15.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: code-acme\n",
            "    Found existing installation: code-acme 0.0\n",
            "    Uninstalling code-acme-0.0:\n",
            "      Successfully uninstalled code-acme-0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bsuite-0.3.5 chex-0.1.0 code-acme-0.0 dataclasses-0.6 distrax-0.1.0 dm-acme-0.2.2 dm-control-0.0.403778684 dm-env-1.5 dm-haiku-0.0.5 dm-launchpad-nightly-0.3.0.dev20211205 dm-reverb-0.6.1 dm-sonnet-2.0.0 execnet-1.9.0 frozendict-2.1.1 glfw-2.4.0 jax-0.2.21 jmp-0.0.2 labmaze-1.0.5 mock-4.0.3 optax-0.1.0 pluggy-1.0.0 pytest-6.2.5 pytest-forked-1.3.0 pytest-xdist-2.4.0 rlax-0.1.1 tensorflow-probability-0.14.1 tfp-nightly-0.14.0.dev20210818 trfl-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uyQu6ibpiuQ",
        "outputId": "da855b28-e4f7-4582-d097-ca2938c5a92b"
      },
      "source": [
        "!pytest"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\n",
            "rootdir: /content/drive/My Drive/code-acme\n",
            "plugins: xdist-2.4.0, forked-1.3.0, typeguard-2.7.1\n",
            "collected 6 items                                                              \u001b[0m\n",
            "\n",
            "environments/MovingCoil0D/test_Moving_Coil.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                     [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 0.86s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj7nFnhbpwTX",
        "outputId": "e4303d78-565e-4a80-db31-3923b7105ba9"
      },
      "source": [
        "ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dockerfile  \u001b[0m\u001b[01;34menvironments\u001b[0m/  \u001b[01;34mexamples\u001b[0m/  README.md  setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3DoIxVppysX",
        "outputId": "368b528e-56c4-4ce2-89f3-3b75535d12d9"
      },
      "source": [
        "cd examples/"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/code-acme/examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyWx1dZEp7kP",
        "outputId": "b863619b-e590-429e-f459-ab3c89fb44af"
      },
      "source": [
        "ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMovingCoil0D\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzJ6-jJsp8x6",
        "outputId": "0da2ede8-1f6f-473f-cda0-68fdd150da1e"
      },
      "source": [
        "cd MovingCoil0D/"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/code-acme/examples/MovingCoil0D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DabQlw2Sp-sy",
        "outputId": "38787764-bdcb-465b-e645-064539c8c419"
      },
      "source": [
        "ls"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval_network_from_snapshot.py  run_mpo.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ3nw2mQp_gD",
        "outputId": "f38dfdf2-cea5-4587-f5be-33efb07b9546"
      },
      "source": [
        "!python run_mpo.py"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\n",
            "2021-12-06 21:31:01.910667: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmplppola12.\n",
            "[reverb/cc/platform/tfrecord_checkpointer.cc:386] Loading latest checkpoint from /tmp/tmplppola12\n",
            "[reverb/cc/platform/default/server.cc:71] Started replay server on port 18731\n",
            "I1206 21:31:03.222313 140093364000640 csv.py:76] Logging to /root/acme/cd0f6372-56db-11ec-a77c-0242ac1c0002/logs/learner/logs.csv\n",
            "2021-12-06 21:31:03.313811: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "I1206 21:31:03.443495 140093364000640 savers.py:167] Attempting to restore checkpoint: None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py:345: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
            "Instructions for updating:\n",
            "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
            "W1206 21:31:05.098922 140093364000640 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py:345: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
            "Instructions for updating:\n",
            "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
            "I1206 21:31:05.161983 140093364000640 csv.py:76] Logging to /root/acme/cd0f6372-56db-11ec-a77c-0242ac1c0002/logs/environment_loop/logs.csv\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py:345: calling Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.\n",
            "Instructions for updating:\n",
            "Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.\n",
            "W1206 21:31:07.766599 140093364000640 deprecation.py:619] From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py:345: calling Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.\n",
            "Instructions for updating:\n",
            "Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.\n",
            "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (558) so Table priority_table is accessed directly without gRPC.\n",
            "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (558) so Table priority_table is accessed directly without gRPC.\n",
            "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (558) so Table priority_table is accessed directly without gRPC.\n",
            "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (558) so Table priority_table is accessed directly without gRPC.\n",
            "I1206 21:31:12.636516 140093364000640 savers.py:157] Saving checkpoint: /root/acme/cd0f6372-56db-11ec-a77c-0242ac1c0002/checkpoints/dmpo_learner\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tfp.distributions.MultivariateNormalDiag_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /root/acme/cd0f6372-56db-11ec-a77c-0242ac1c0002/snapshots/policy/assets\n",
            "I1206 21:31:13.250500 140093364000640 builder_impl.py:784] Assets written to: /root/acme/cd0f6372-56db-11ec-a77c-0242ac1c0002/snapshots/policy/assets\n",
            "I1206 21:31:13.260735 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.978 | Dual Alpha Mean = 1.313 | Dual Alpha Stddev = 10.000 | Dual Temperature = 1.313 | Kl Mean Rel = [0. 0.] | Kl Q Rel = 13.801 | Kl Stddev Rel = [0. 0.] | Loss Alpha = 0.003 | Loss Policy = 9.730 | Loss Temperature = 7.071 | Penalty Kl Q Rel = 0.000 | Pi Stddev Cond = 1.002 | Pi Stddev Max = 0.300 | Pi Stddev Min = 0.299 | Policy Loss = [9.7295475] | Q Max = 9.573 | Q Min = -7.886 | Steps = 1 | Walltime = 0\n",
            "I1206 21:31:13.658730 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 9.386466026306152 | Episodes = 1 | Steps = 101 | Steps Per Second = 11.887\n",
            "I1206 21:31:14.266298 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.813 | Dual Alpha Mean = 0.937 | Dual Alpha Stddev = 11.294 | Dual Temperature = 2.034 | Kl Mean Rel = [0.06615934 0.05117023] | Kl Q Rel = 1.996 | Kl Stddev Rel = [20.836357 27.714075] | Loss Alpha = 0.001 | Loss Policy = 10.114 | Loss Temperature = 10.841 | Penalty Kl Q Rel = 0.142 | Pi Stddev Cond = 1.261 | Pi Stddev Max = 0.271 | Pi Stddev Min = 0.216 | Policy Loss = [10.113961] | Q Max = 12.062 | Q Min = 7.324 | Steps = 174 | Walltime = 1.629\n",
            "I1206 21:31:14.719466 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 34 | Episode Return = 7.1243791580200195 | Episodes = 6 | Steps = 277 | Steps Per Second = 158.575\n",
            "I1206 21:31:15.268201 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.424 | Dual Alpha Mean = 0.551 | Dual Alpha Stddev = 12.033 | Dual Temperature = 2.098 | Kl Mean Rel = [0.07822714 1.2920642 ] | Kl Q Rel = 0.350 | Kl Stddev Rel = [106.02894   56.690887] | Loss Alpha = -0.002 | Loss Policy = 11.915 | Loss Temperature = 13.700 | Penalty Kl Q Rel = 0.003 | Pi Stddev Cond = 1.290 | Pi Stddev Max = 0.221 | Pi Stddev Min = 0.171 | Policy Loss = [11.915385] | Q Max = 14.135 | Q Min = 12.038 | Steps = 340 | Walltime = 2.631\n",
            "I1206 21:31:15.878464 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 32 | Episode Return = 7.164499759674072 | Episodes = 12 | Steps = 469 | Steps Per Second = 172.394\n",
            "I1206 21:31:16.273396 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.595 | Dual Alpha Mean = 0.543 | Dual Alpha Stddev = 12.262 | Dual Temperature = 1.987 | Kl Mean Rel = [0.7289984 1.2425543] | Kl Q Rel = 0.737 | Kl Stddev Rel = [71.98705    7.0382714] | Loss Alpha = -0.001 | Loss Policy = 7.666 | Loss Temperature = 8.877 | Penalty Kl Q Rel = 2.607 | Pi Stddev Cond = 1.231 | Pi Stddev Max = 0.231 | Pi Stddev Min = 0.189 | Policy Loss = [7.6660905] | Q Max = 9.847 | Q Min = 7.166 | Steps = 506 | Walltime = 3.636\n",
            "I1206 21:31:16.941863 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 64 | Episode Return = 15.454038619995117 | Episodes = 17 | Steps = 647 | Steps Per Second = 173.805\n",
            "I1206 21:31:17.273772 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.918 | Dual Alpha Mean = 0.549 | Dual Alpha Stddev = 12.435 | Dual Temperature = 1.822 | Kl Mean Rel = [0.64511925 0.31271154] | Kl Q Rel = 0.880 | Kl Stddev Rel = [3.218811 6.105269] | Loss Alpha = 0.001 | Loss Policy = 8.955 | Loss Temperature = 10.097 | Penalty Kl Q Rel = 1.407 | Pi Stddev Cond = 1.239 | Pi Stddev Max = 0.240 | Pi Stddev Min = 0.195 | Policy Loss = [8.954717] | Q Max = 10.968 | Q Min = 8.365 | Steps = 675 | Walltime = 4.637\n",
            "I1206 21:31:17.990116 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 45 | Episode Return = 14.27871322631836 | Episodes = 22 | Steps = 828 | Steps Per Second = 180.303\n",
            "I1206 21:31:18.274851 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.488 | Dual Alpha Mean = 0.316 | Dual Alpha Stddev = 12.691 | Dual Temperature = 1.767 | Kl Mean Rel = [0.29296532 0.9704122 ] | Kl Q Rel = 1.005 | Kl Stddev Rel = [50.326706 45.535072] | Loss Alpha = -0.001 | Loss Policy = 7.800 | Loss Temperature = 9.030 | Penalty Kl Q Rel = 1.104 | Pi Stddev Cond = 1.215 | Pi Stddev Max = 0.237 | Pi Stddev Min = 0.197 | Policy Loss = [7.800075] | Q Max = 9.701 | Q Min = 7.477 | Steps = 849 | Walltime = 5.638\n",
            "I1206 21:31:19.218280 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 42 | Episode Return = 9.849604606628418 | Episodes = 26 | Steps = 1035 | Steps Per Second = 166.185\n",
            "I1206 21:31:19.275395 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.618 | Dual Alpha Mean = 0.236 | Dual Alpha Stddev = 13.409 | Dual Temperature = 1.700 | Kl Mean Rel = [0.8620873  0.12488619] | Kl Q Rel = 0.794 | Kl Stddev Rel = [12.725895  9.614528] | Loss Alpha = 0.000 | Loss Policy = 8.902 | Loss Temperature = 11.751 | Penalty Kl Q Rel = 0.447 | Pi Stddev Cond = 1.249 | Pi Stddev Max = 0.208 | Pi Stddev Min = 0.169 | Policy Loss = [8.901791] | Q Max = 12.417 | Q Min = 10.036 | Steps = 1015 | Walltime = 6.638\n",
            "I1206 21:31:20.279683 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.552 | Dual Alpha Mean = 0.194 | Dual Alpha Stddev = 13.930 | Dual Temperature = 1.439 | Kl Mean Rel = [0.01912864 0.13021936] | Kl Q Rel = 0.754 | Kl Stddev Rel = [1.8635068  0.72497493] | Loss Alpha = 0.000 | Loss Policy = 9.805 | Loss Temperature = 13.078 | Penalty Kl Q Rel = 0.503 | Pi Stddev Cond = 1.303 | Pi Stddev Max = 0.187 | Pi Stddev Min = 0.147 | Policy Loss = [9.804706] | Q Max = 13.498 | Q Min = 11.905 | Steps = 1192 | Walltime = 7.642\n",
            "I1206 21:31:20.376973 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 16.05357551574707 | Episodes = 28 | Steps = 1237 | Steps Per Second = 176.530\n",
            "I1206 21:31:21.282310 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.118 | Dual Alpha Mean = 0.291 | Dual Alpha Stddev = 14.223 | Dual Temperature = 1.286 | Kl Mean Rel = [0.06186335 0.7674241 ] | Kl Q Rel = 0.653 | Kl Stddev Rel = [7.3838425  0.72997075] | Loss Alpha = 0.000 | Loss Policy = 7.743 | Loss Temperature = 10.939 | Penalty Kl Q Rel = 0.698 | Pi Stddev Cond = 1.320 | Pi Stddev Max = 0.192 | Pi Stddev Min = 0.148 | Policy Loss = [7.74308] | Q Max = 11.449 | Q Min = 9.814 | Steps = 1363 | Walltime = 8.645\n",
            "I1206 21:31:21.569994 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 14.868876457214355 | Episodes = 30 | Steps = 1439 | Steps Per Second = 167.597\n",
            "I1206 21:31:22.283365 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.677 | Dual Alpha Mean = 1.108 | Dual Alpha Stddev = 14.600 | Dual Temperature = 1.204 | Kl Mean Rel = [0.12547795 0.55978763] | Kl Q Rel = 0.801 | Kl Stddev Rel = [ 1.3330793 22.328846 ] | Loss Alpha = 0.001 | Loss Policy = 8.839 | Loss Temperature = 11.942 | Penalty Kl Q Rel = 1.401 | Pi Stddev Cond = 1.432 | Pi Stddev Max = 0.200 | Pi Stddev Min = 0.144 | Policy Loss = [8.839] | Q Max = 12.473 | Q Min = 10.862 | Steps = 1533 | Walltime = 9.646\n",
            "I1206 21:31:22.743703 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 35.065338134765625 | Episodes = 32 | Steps = 1641 | Steps Per Second = 172.350\n",
            "I1206 21:31:23.286938 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.801 | Dual Alpha Mean = 1.464 | Dual Alpha Stddev = 15.013 | Dual Temperature = 1.130 | Kl Mean Rel = [0.3921676  0.48963565] | Kl Q Rel = 0.984 | Kl Stddev Rel = [4.688059 2.109265] | Loss Alpha = 0.001 | Loss Policy = 8.842 | Loss Temperature = 11.380 | Penalty Kl Q Rel = 1.045 | Pi Stddev Cond = 1.462 | Pi Stddev Max = 0.212 | Pi Stddev Min = 0.150 | Policy Loss = [8.841981] | Q Max = 11.965 | Q Min = 10.281 | Steps = 1705 | Walltime = 10.650\n",
            "I1206 21:31:23.923151 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 74.85842895507812 | Episodes = 34 | Steps = 1843 | Steps Per Second = 172.276\n",
            "I1206 21:31:24.290877 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.031 | Dual Alpha Mean = 1.198 | Dual Alpha Stddev = 15.279 | Dual Temperature = 0.856 | Kl Mean Rel = [2.2865474  0.38514188] | Kl Q Rel = 0.477 | Kl Stddev Rel = [19.03106    0.6558399] | Loss Alpha = 0.001 | Loss Policy = 12.359 | Loss Temperature = 16.927 | Penalty Kl Q Rel = 0.571 | Pi Stddev Cond = 1.562 | Pi Stddev Max = 0.178 | Pi Stddev Min = 0.117 | Policy Loss = [12.359326] | Q Max = 17.197 | Q Min = 16.176 | Steps = 1875 | Walltime = 11.653\n",
            "I1206 21:31:25.134417 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 70.11192321777344 | Episodes = 36 | Steps = 2045 | Steps Per Second = 167.766\n",
            "I1206 21:31:25.295064 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.000 | Dual Alpha Mean = 1.481 | Dual Alpha Stddev = 15.952 | Dual Temperature = 0.646 | Kl Mean Rel = [1.0256624  0.07885955] | Kl Q Rel = 0.475 | Kl Stddev Rel = [4.0547223 4.2043085] | Loss Alpha = 0.001 | Loss Policy = 15.743 | Loss Temperature = 20.044 | Penalty Kl Q Rel = 0.565 | Pi Stddev Cond = 1.463 | Pi Stddev Max = 0.177 | Pi Stddev Min = 0.125 | Policy Loss = [15.743065] | Q Max = 20.236 | Q Min = 19.518 | Steps = 2044 | Walltime = 12.658\n",
            "I1206 21:31:26.297533 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.992 | Dual Alpha Mean = 1.205 | Dual Alpha Stddev = 17.095 | Dual Temperature = 0.506 | Kl Mean Rel = [4.5504236 4.0494533] | Kl Q Rel = 0.728 | Kl Stddev Rel = [30.657825 15.171162] | Loss Alpha = -0.009 | Loss Policy = 16.938 | Loss Temperature = 23.240 | Penalty Kl Q Rel = 0.464 | Pi Stddev Cond = 1.460 | Pi Stddev Max = 0.141 | Pi Stddev Min = 0.099 | Policy Loss = [16.937836] | Q Max = 23.460 | Q Min = 22.653 | Steps = 2215 | Walltime = 13.660\n",
            "I1206 21:31:26.318292 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 85.760498046875 | Episodes = 38 | Steps = 2247 | Steps Per Second = 170.690\n",
            "I1206 21:31:27.300091 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.145 | Dual Alpha Mean = 1.252 | Dual Alpha Stddev = 18.218 | Dual Temperature = 0.414 | Kl Mean Rel = [0.9261782  0.70734775] | Kl Q Rel = 0.769 | Kl Stddev Rel = [12.08678    6.2014384] | Loss Alpha = 0.000 | Loss Policy = 16.811 | Loss Temperature = 23.494 | Penalty Kl Q Rel = 1.044 | Pi Stddev Cond = 1.415 | Pi Stddev Max = 0.144 | Pi Stddev Min = 0.106 | Policy Loss = [16.811354] | Q Max = 23.728 | Q Min = 22.986 | Steps = 2384 | Walltime = 14.663\n",
            "I1206 21:31:27.506071 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 98.95376586914062 | Episodes = 40 | Steps = 2449 | Steps Per Second = 170.432\n",
            "I1206 21:31:28.303682 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.100 | Dual Alpha Mean = 1.335 | Dual Alpha Stddev = 19.403 | Dual Temperature = 0.359 | Kl Mean Rel = [0.06393956 0.05267499] | Kl Q Rel = 0.905 | Kl Stddev Rel = [91.860725 60.686855] | Loss Alpha = -0.000 | Loss Policy = 20.515 | Loss Temperature = 29.209 | Penalty Kl Q Rel = 0.538 | Pi Stddev Cond = 1.466 | Pi Stddev Max = 0.104 | Pi Stddev Min = 0.073 | Policy Loss = [20.515041] | Q Max = 29.419 | Q Min = 28.786 | Steps = 2558 | Walltime = 15.667\n",
            "I1206 21:31:28.671106 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 99.99362182617188 | Episodes = 42 | Steps = 2651 | Steps Per Second = 174.085\n",
            "I1206 21:31:29.304793 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.992 | Dual Alpha Mean = 1.777 | Dual Alpha Stddev = 20.248 | Dual Temperature = 0.352 | Kl Mean Rel = [1.1534102 1.7134726] | Kl Q Rel = 0.902 | Kl Stddev Rel = [1.9050556  0.20357506] | Loss Alpha = -0.002 | Loss Policy = 19.773 | Loss Temperature = 27.529 | Penalty Kl Q Rel = 1.174 | Pi Stddev Cond = 1.338 | Pi Stddev Max = 0.118 | Pi Stddev Min = 0.095 | Policy Loss = [19.773481] | Q Max = 27.857 | Q Min = 27.192 | Steps = 2733 | Walltime = 16.668\n",
            "I1206 21:31:29.842158 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 99.45896911621094 | Episodes = 44 | Steps = 2853 | Steps Per Second = 171.697\n",
            "I1206 21:31:30.305366 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.087 | Dual Alpha Mean = 2.256 | Dual Alpha Stddev = 20.819 | Dual Temperature = 0.366 | Kl Mean Rel = [0.2887326 2.6297257] | Kl Q Rel = 1.330 | Kl Stddev Rel = [1.6812878 6.4770985] | Loss Alpha = -0.001 | Loss Policy = 18.429 | Loss Temperature = 26.978 | Penalty Kl Q Rel = 1.500 | Pi Stddev Cond = 1.450 | Pi Stddev Max = 0.116 | Pi Stddev Min = 0.079 | Policy Loss = [18.42883] | Q Max = 27.448 | Q Min = 26.845 | Steps = 2904 | Walltime = 17.668\n",
            "I1206 21:31:31.039963 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 99.6888656616211 | Episodes = 46 | Steps = 3055 | Steps Per Second = 167.705\n",
            "I1206 21:31:31.306095 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.060 | Dual Alpha Mean = 2.367 | Dual Alpha Stddev = 21.515 | Dual Temperature = 0.353 | Kl Mean Rel = [5.091197  2.8821092] | Kl Q Rel = 0.619 | Kl Stddev Rel = [0.6085582 2.108652 ] | Loss Alpha = -0.015 | Loss Policy = 25.376 | Loss Temperature = 35.783 | Penalty Kl Q Rel = 0.310 | Pi Stddev Cond = 1.424 | Pi Stddev Max = 0.083 | Pi Stddev Min = 0.059 | Policy Loss = [25.376085] | Q Max = 35.982 | Q Min = 35.526 | Steps = 3072 | Walltime = 18.669\n",
            "I1206 21:31:32.197603 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 99.97814178466797 | Episodes = 48 | Steps = 3257 | Steps Per Second = 180.780\n",
            "I1206 21:31:32.309831 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.000 | Dual Alpha Mean = 3.489 | Dual Alpha Stddev = 22.077 | Dual Temperature = 0.353 | Kl Mean Rel = [0.4361438  0.11624403] | Kl Q Rel = 1.505 | Kl Stddev Rel = [12.017245   6.4866686] | Loss Alpha = 0.005 | Loss Policy = 19.677 | Loss Temperature = 27.656 | Penalty Kl Q Rel = 1.662 | Pi Stddev Cond = 1.648 | Pi Stddev Max = 0.146 | Pi Stddev Min = 0.086 | Policy Loss = [19.67708] | Q Max = 28.271 | Q Min = 27.582 | Steps = 3249 | Walltime = 19.673\n",
            "I1206 21:31:33.312921 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.066 | Dual Alpha Mean = 4.622 | Dual Alpha Stddev = 22.639 | Dual Temperature = 0.382 | Kl Mean Rel = [0.7122551 0.8736764] | Kl Q Rel = 0.741 | Kl Stddev Rel = [50.81252    7.7536144] | Loss Alpha = 0.001 | Loss Policy = 26.789 | Loss Temperature = 37.345 | Penalty Kl Q Rel = 0.886 | Pi Stddev Cond = 1.522 | Pi Stddev Max = 0.094 | Pi Stddev Min = 0.057 | Policy Loss = [26.789389] | Q Max = 37.707 | Q Min = 37.164 | Steps = 3427 | Walltime = 20.676\n",
            "I1206 21:31:33.334527 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 97.165283203125 | Episodes = 50 | Steps = 3459 | Steps Per Second = 169.589\n",
            "I1206 21:31:34.315689 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.081 | Dual Alpha Mean = 4.956 | Dual Alpha Stddev = 23.296 | Dual Temperature = 0.389 | Kl Mean Rel = [0.18947539 0.19645533] | Kl Q Rel = 1.041 | Kl Stddev Rel = [ 2.2395008 48.071728 ] | Loss Alpha = 0.007 | Loss Policy = 29.020 | Loss Temperature = 40.202 | Penalty Kl Q Rel = 0.832 | Pi Stddev Cond = 1.626 | Pi Stddev Max = 0.088 | Pi Stddev Min = 0.050 | Policy Loss = [29.020199] | Q Max = 40.613 | Q Min = 39.932 | Steps = 3600 | Walltime = 21.679\n",
            "I1206 21:31:34.515450 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 94.1793212890625 | Episodes = 52 | Steps = 3661 | Steps Per Second = 169.274\n",
            "I1206 21:31:35.319048 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.074 | Dual Alpha Mean = 5.059 | Dual Alpha Stddev = 23.814 | Dual Temperature = 0.460 | Kl Mean Rel = [0.02779908 2.2900088 ] | Kl Q Rel = 0.767 | Kl Stddev Rel = [0.09688763 0.6804927 ] | Loss Alpha = -0.000 | Loss Policy = 24.652 | Loss Temperature = 35.369 | Penalty Kl Q Rel = 1.074 | Pi Stddev Cond = 1.774 | Pi Stddev Max = 0.102 | Pi Stddev Min = 0.052 | Policy Loss = [24.65168] | Q Max = 35.791 | Q Min = 35.019 | Steps = 3772 | Walltime = 22.682\n",
            "I1206 21:31:35.689824 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 92.3993911743164 | Episodes = 54 | Steps = 3863 | Steps Per Second = 168.769\n",
            "I1206 21:31:36.320846 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.943 | Dual Alpha Mean = 5.297 | Dual Alpha Stddev = 24.157 | Dual Temperature = 0.478 | Kl Mean Rel = [0. 0.] | Kl Q Rel = 0.343 | Kl Stddev Rel = [0. 0.] | Loss Alpha = 0.011 | Loss Policy = 29.151 | Loss Temperature = 40.862 | Penalty Kl Q Rel = 0.423 | Pi Stddev Cond = 1.759 | Pi Stddev Max = 0.087 | Pi Stddev Min = 0.048 | Policy Loss = [29.150585] | Q Max = 41.083 | Q Min = 40.680 | Steps = 3941 | Walltime = 23.684\n",
            "I1206 21:31:36.876238 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 88.05093383789062 | Episodes = 56 | Steps = 4065 | Steps Per Second = 171.033\n",
            "I1206 21:31:37.323863 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.056 | Dual Alpha Mean = 5.801 | Dual Alpha Stddev = 24.609 | Dual Temperature = 0.388 | Kl Mean Rel = [0.46095803 7.5579114 ] | Kl Q Rel = 0.851 | Kl Stddev Rel = [ 5.48767  10.957965] | Loss Alpha = -0.033 | Loss Policy = 28.198 | Loss Temperature = 39.631 | Penalty Kl Q Rel = 1.601 | Pi Stddev Cond = 1.928 | Pi Stddev Max = 0.100 | Pi Stddev Min = 0.046 | Policy Loss = [28.197765] | Q Max = 39.917 | Q Min = 39.258 | Steps = 4114 | Walltime = 24.687\n",
            "I1206 21:31:38.042738 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 83.62735748291016 | Episodes = 58 | Steps = 4267 | Steps Per Second = 174.098\n",
            "I1206 21:31:38.325661 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.053 | Dual Alpha Mean = 6.443 | Dual Alpha Stddev = 25.159 | Dual Temperature = 0.386 | Kl Mean Rel = [0.27253568 0.520883  ] | Kl Q Rel = 1.768 | Kl Stddev Rel = [ 6.167928 15.978887] | Loss Alpha = 0.007 | Loss Policy = 31.045 | Loss Temperature = 42.899 | Penalty Kl Q Rel = 1.389 | Pi Stddev Cond = 2.191 | Pi Stddev Max = 0.126 | Pi Stddev Min = 0.045 | Policy Loss = [31.04472] | Q Max = 43.306 | Q Min = 42.641 | Steps = 4286 | Walltime = 25.688\n",
            "I1206 21:31:39.229822 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 84.39202117919922 | Episodes = 60 | Steps = 4469 | Steps Per Second = 173.716\n",
            "I1206 21:31:39.327727 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.008 | Dual Alpha Mean = 6.665 | Dual Alpha Stddev = 25.584 | Dual Temperature = 0.373 | Kl Mean Rel = [0.8305049  0.13597278] | Kl Q Rel = 0.619 | Kl Stddev Rel = [13.863975   1.6288822] | Loss Alpha = 0.007 | Loss Policy = 29.873 | Loss Temperature = 42.475 | Penalty Kl Q Rel = 0.348 | Pi Stddev Cond = 1.753 | Pi Stddev Max = 0.078 | Pi Stddev Min = 0.041 | Policy Loss = [29.87309] | Q Max = 42.678 | Q Min = 42.280 | Steps = 4457 | Walltime = 26.691\n",
            "I1206 21:31:40.330614 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.990 | Dual Alpha Mean = 6.836 | Dual Alpha Stddev = 25.968 | Dual Temperature = 0.398 | Kl Mean Rel = [0.13334535 0.3238834 ] | Kl Q Rel = 0.188 | Kl Stddev Rel = [5.0398054 9.531928 ] | Loss Alpha = 0.010 | Loss Policy = 30.499 | Loss Temperature = 42.928 | Penalty Kl Q Rel = 0.213 | Pi Stddev Cond = 1.674 | Pi Stddev Max = 0.077 | Pi Stddev Min = 0.042 | Policy Loss = [30.499222] | Q Max = 43.149 | Q Min = 42.871 | Steps = 4629 | Walltime = 27.693\n",
            "I1206 21:31:40.415953 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 80.89844512939453 | Episodes = 62 | Steps = 4671 | Steps Per Second = 173.461\n",
            "I1206 21:31:41.336799 140093364000640 terminal.py:91] [Learner] Critic Loss = 3.032 | Dual Alpha Mean = 7.035 | Dual Alpha Stddev = 26.751 | Dual Temperature = 0.379 | Kl Mean Rel = [0.347222   0.11429397] | Kl Q Rel = 1.392 | Kl Stddev Rel = [ 3.7858844 27.15005  ] | Loss Alpha = 0.010 | Loss Policy = 29.522 | Loss Temperature = 40.810 | Penalty Kl Q Rel = 2.495 | Pi Stddev Cond = 2.520 | Pi Stddev Max = 0.138 | Pi Stddev Min = 0.044 | Policy Loss = [29.521576] | Q Max = 41.240 | Q Min = 40.401 | Steps = 4797 | Walltime = 28.700\n",
            "I1206 21:31:41.633277 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 77.6553726196289 | Episodes = 64 | Steps = 4873 | Steps Per Second = 165.496\n",
            "I1206 21:31:42.339478 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.957 | Dual Alpha Mean = 7.537 | Dual Alpha Stddev = 27.182 | Dual Temperature = 0.358 | Kl Mean Rel = [11.872741  8.817738] | Kl Q Rel = 0.208 | Kl Stddev Rel = [ 1.3819731 52.99373  ] | Loss Alpha = -0.142 | Loss Policy = 31.287 | Loss Temperature = 44.758 | Penalty Kl Q Rel = 0.042 | Pi Stddev Cond = 1.495 | Pi Stddev Max = 0.056 | Pi Stddev Min = 0.038 | Policy Loss = [31.286846] | Q Max = 44.826 | Q Min = 44.578 | Steps = 4964 | Walltime = 29.702\n",
            "I1206 21:31:42.809351 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 73.79503631591797 | Episodes = 66 | Steps = 5075 | Steps Per Second = 174.028\n",
            "I1206 21:31:43.342360 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.908 | Dual Alpha Mean = 8.248 | Dual Alpha Stddev = 27.663 | Dual Temperature = 0.337 | Kl Mean Rel = [0.43046057 0.5523342 ] | Kl Q Rel = 0.490 | Kl Stddev Rel = [ 0.603449 11.229422] | Loss Alpha = 0.008 | Loss Policy = 30.403 | Loss Temperature = 43.589 | Penalty Kl Q Rel = 0.275 | Pi Stddev Cond = 2.483 | Pi Stddev Max = 0.079 | Pi Stddev Min = 0.036 | Policy Loss = [30.403423] | Q Max = 43.927 | Q Min = 43.595 | Steps = 5138 | Walltime = 30.705\n",
            "I1206 21:31:44.002384 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 74.94444274902344 | Episodes = 68 | Steps = 5277 | Steps Per Second = 167.788\n",
            "I1206 21:31:44.343323 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.915 | Dual Alpha Mean = 8.576 | Dual Alpha Stddev = 28.110 | Dual Temperature = 0.333 | Kl Mean Rel = [17.865223 18.803837] | Kl Q Rel = 0.219 | Kl Stddev Rel = [  2.5332363 102.672134 ] | Loss Alpha = -0.301 | Loss Policy = 28.812 | Loss Temperature = 42.113 | Penalty Kl Q Rel = 0.062 | Pi Stddev Cond = 1.493 | Pi Stddev Max = 0.056 | Pi Stddev Min = 0.037 | Policy Loss = [28.81155] | Q Max = 42.229 | Q Min = 41.997 | Steps = 5303 | Walltime = 31.706\n",
            "I1206 21:31:45.229741 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 79.738037109375 | Episodes = 70 | Steps = 5479 | Steps Per Second = 169.446\n",
            "I1206 21:31:45.344673 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.946 | Dual Alpha Mean = 10.174 | Dual Alpha Stddev = 29.048 | Dual Temperature = 0.348 | Kl Mean Rel = [ 1.6608772 21.051617 ] | Kl Q Rel = 0.544 | Kl Stddev Rel = [ 2.4569552 52.552082 ] | Loss Alpha = -0.227 | Loss Policy = 27.490 | Loss Temperature = 40.015 | Penalty Kl Q Rel = 0.514 | Pi Stddev Cond = 2.524 | Pi Stddev Max = 0.086 | Pi Stddev Min = 0.038 | Policy Loss = [27.489738] | Q Max = 40.362 | Q Min = 39.899 | Steps = 5470 | Walltime = 32.707\n",
            "I1206 21:31:46.346492 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.923 | Dual Alpha Mean = 10.666 | Dual Alpha Stddev = 30.057 | Dual Temperature = 0.388 | Kl Mean Rel = [0.38370478 1.0810081 ] | Kl Q Rel = 0.267 | Kl Stddev Rel = [ 0.0748354 11.672218 ] | Loss Alpha = 0.005 | Loss Policy = 28.332 | Loss Temperature = 40.684 | Penalty Kl Q Rel = 0.298 | Pi Stddev Cond = 2.201 | Pi Stddev Max = 0.080 | Pi Stddev Min = 0.040 | Policy Loss = [28.331772] | Q Max = 40.972 | Q Min = 40.665 | Steps = 5639 | Walltime = 33.709\n",
            "I1206 21:31:46.425209 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 77.67047119140625 | Episodes = 72 | Steps = 5681 | Steps Per Second = 170.622\n",
            "I1206 21:31:47.348730 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.972 | Dual Alpha Mean = 10.855 | Dual Alpha Stddev = 30.672 | Dual Temperature = 0.381 | Kl Mean Rel = [0.41045982 1.1842265 ] | Kl Q Rel = 1.623 | Kl Stddev Rel = [0.31095636 4.370456  ] | Loss Alpha = 0.004 | Loss Policy = 27.684 | Loss Temperature = 39.225 | Penalty Kl Q Rel = 1.705 | Pi Stddev Cond = 2.336 | Pi Stddev Max = 0.119 | Pi Stddev Min = 0.044 | Policy Loss = [27.68391] | Q Max = 39.587 | Q Min = 38.703 | Steps = 5812 | Walltime = 34.712\n",
            "I1206 21:31:47.598426 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 77.50453186035156 | Episodes = 74 | Steps = 5883 | Steps Per Second = 170.200\n",
            "I1206 21:31:48.352231 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.930 | Dual Alpha Mean = 11.282 | Dual Alpha Stddev = 31.512 | Dual Temperature = 0.375 | Kl Mean Rel = [0.34295616 0.241572  ] | Kl Q Rel = 1.420 | Kl Stddev Rel = [7.162147 1.855279] | Loss Alpha = 0.016 | Loss Policy = 30.760 | Loss Temperature = 42.368 | Penalty Kl Q Rel = 0.812 | Pi Stddev Cond = 1.978 | Pi Stddev Max = 0.087 | Pi Stddev Min = 0.043 | Policy Loss = [30.760193] | Q Max = 42.659 | Q Min = 41.925 | Steps = 5977 | Walltime = 35.715\n",
            "I1206 21:31:48.864544 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 77.93016815185547 | Episodes = 76 | Steps = 6085 | Steps Per Second = 156.768\n",
            "I1206 21:31:49.355739 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.891 | Dual Alpha Mean = 11.436 | Dual Alpha Stddev = 32.270 | Dual Temperature = 0.376 | Kl Mean Rel = [0.2050157 0.6981203] | Kl Q Rel = 0.794 | Kl Stddev Rel = [0.15869276 0.40334758] | Loss Alpha = 0.012 | Loss Policy = 31.676 | Loss Temperature = 43.292 | Penalty Kl Q Rel = 0.389 | Pi Stddev Cond = 2.226 | Pi Stddev Max = 0.087 | Pi Stddev Min = 0.044 | Policy Loss = [31.676086] | Q Max = 43.560 | Q Min = 42.893 | Steps = 6136 | Walltime = 36.718\n",
            "I1206 21:31:50.098787 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 76.55859375 | Episodes = 78 | Steps = 6287 | Steps Per Second = 165.255\n",
            "I1206 21:31:50.357990 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.891 | Dual Alpha Mean = 11.558 | Dual Alpha Stddev = 33.403 | Dual Temperature = 0.420 | Kl Mean Rel = [0. 0.] | Kl Q Rel = 0.687 | Kl Stddev Rel = [0. 0.] | Loss Alpha = 0.023 | Loss Policy = 30.678 | Loss Temperature = 41.561 | Penalty Kl Q Rel = 0.883 | Pi Stddev Cond = 2.496 | Pi Stddev Max = 0.134 | Pi Stddev Min = 0.048 | Policy Loss = [30.677567] | Q Max = 41.931 | Q Min = 41.447 | Steps = 6301 | Walltime = 37.721\n",
            "I1206 21:31:51.258166 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 80.43096160888672 | Episodes = 80 | Steps = 6489 | Steps Per Second = 184.324\n",
            "I1206 21:31:51.362281 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.893 | Dual Alpha Mean = 12.019 | Dual Alpha Stddev = 34.544 | Dual Temperature = 0.529 | Kl Mean Rel = [5.004399  2.9694228] | Kl Q Rel = 0.875 | Kl Stddev Rel = [67.25459 53.79835] | Loss Alpha = -0.072 | Loss Policy = 29.888 | Loss Temperature = 40.783 | Penalty Kl Q Rel = 0.926 | Pi Stddev Cond = 1.938 | Pi Stddev Max = 0.114 | Pi Stddev Min = 0.050 | Policy Loss = [29.887573] | Q Max = 41.122 | Q Min = 40.208 | Steps = 6479 | Walltime = 38.725\n",
            "I1206 21:31:52.365790 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.813 | Dual Alpha Mean = 12.767 | Dual Alpha Stddev = 35.700 | Dual Temperature = 0.482 | Kl Mean Rel = [2.344917   0.06283646] | Kl Q Rel = 1.165 | Kl Stddev Rel = [7.2804384 4.1612577] | Loss Alpha = -0.001 | Loss Policy = 32.030 | Loss Temperature = 42.295 | Penalty Kl Q Rel = 0.068 | Pi Stddev Cond = 1.670 | Pi Stddev Max = 0.083 | Pi Stddev Min = 0.056 | Policy Loss = [32.029694] | Q Max = 42.601 | Q Min = 41.893 | Steps = 6659 | Walltime = 39.729\n",
            "I1206 21:31:52.386278 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 78.17152404785156 | Episodes = 82 | Steps = 6691 | Steps Per Second = 177.142\n",
            "I1206 21:31:53.367277 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.908 | Dual Alpha Mean = 13.432 | Dual Alpha Stddev = 37.366 | Dual Temperature = 0.698 | Kl Mean Rel = [0.49314362 1.0901101 ] | Kl Q Rel = 1.307 | Kl Stddev Rel = [ 5.1579256 41.761963 ] | Loss Alpha = 0.003 | Loss Policy = 29.520 | Loss Temperature = 38.979 | Penalty Kl Q Rel = 2.767 | Pi Stddev Cond = 2.286 | Pi Stddev Max = 0.155 | Pi Stddev Min = 0.056 | Policy Loss = [29.520214] | Q Max = 39.489 | Q Min = 38.169 | Steps = 6835 | Walltime = 40.730\n",
            "I1206 21:31:53.535022 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 79.70089721679688 | Episodes = 84 | Steps = 6893 | Steps Per Second = 173.602\n",
            "I1206 21:31:54.371167 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.861 | Dual Alpha Mean = 13.502 | Dual Alpha Stddev = 38.451 | Dual Temperature = 0.713 | Kl Mean Rel = [3.500456 6.832313] | Kl Q Rel = 0.571 | Kl Stddev Rel = [ 0.5611141 42.637234 ] | Loss Alpha = -0.121 | Loss Policy = 33.187 | Loss Temperature = 43.419 | Penalty Kl Q Rel = 0.035 | Pi Stddev Cond = 1.553 | Pi Stddev Max = 0.079 | Pi Stddev Min = 0.057 | Policy Loss = [33.18694] | Q Max = 43.762 | Q Min = 43.120 | Steps = 7012 | Walltime = 41.734\n",
            "I1206 21:31:54.680798 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 83.82067108154297 | Episodes = 86 | Steps = 7095 | Steps Per Second = 177.305\n",
            "I1206 21:31:55.372853 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.881 | Dual Alpha Mean = 13.687 | Dual Alpha Stddev = 39.428 | Dual Temperature = 1.016 | Kl Mean Rel = [2.2950284 0.9327615] | Kl Q Rel = 1.562 | Kl Stddev Rel = [ 1.4540398 23.368723 ] | Loss Alpha = -0.015 | Loss Policy = 30.937 | Loss Temperature = 39.435 | Penalty Kl Q Rel = 1.456 | Pi Stddev Cond = 2.367 | Pi Stddev Max = 0.163 | Pi Stddev Min = 0.062 | Policy Loss = [30.937376] | Q Max = 40.259 | Q Min = 38.311 | Steps = 7182 | Walltime = 42.736\n",
            "I1206 21:31:55.906415 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 88.0772933959961 | Episodes = 88 | Steps = 7297 | Steps Per Second = 163.744\n",
            "I1206 21:31:56.374579 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.971 | Dual Alpha Mean = 13.707 | Dual Alpha Stddev = 40.115 | Dual Temperature = 1.037 | Kl Mean Rel = [0.01940876 2.5842087 ] | Kl Q Rel = 1.372 | Kl Stddev Rel = [23.655138  7.445954] | Loss Alpha = -0.016 | Loss Policy = 30.702 | Loss Temperature = 38.700 | Penalty Kl Q Rel = 2.161 | Pi Stddev Cond = 3.614 | Pi Stddev Max = 0.193 | Pi Stddev Min = 0.061 | Policy Loss = [30.70235] | Q Max = 39.706 | Q Min = 37.790 | Steps = 7345 | Walltime = 43.737\n",
            "I1206 21:31:57.128445 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 88.81262969970703 | Episodes = 90 | Steps = 7499 | Steps Per Second = 170.218\n",
            "I1206 21:31:57.380269 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.936 | Dual Alpha Mean = 13.908 | Dual Alpha Stddev = 40.883 | Dual Temperature = 1.091 | Kl Mean Rel = [0. 0.] | Kl Q Rel = 0.711 | Kl Stddev Rel = [0. 0.] | Loss Alpha = 0.028 | Loss Policy = 31.665 | Loss Temperature = 40.842 | Penalty Kl Q Rel = 0.809 | Pi Stddev Cond = 2.962 | Pi Stddev Max = 0.128 | Pi Stddev Min = 0.060 | Policy Loss = [31.665188] | Q Max = 41.426 | Q Min = 40.158 | Steps = 7511 | Walltime = 44.743\n",
            "I1206 21:31:58.318609 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 91.27262115478516 | Episodes = 92 | Steps = 7701 | Steps Per Second = 173.489\n",
            "I1206 21:31:58.383188 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.913 | Dual Alpha Mean = 13.850 | Dual Alpha Stddev = 41.405 | Dual Temperature = 1.255 | Kl Mean Rel = [0.25029302 1.7459145 ] | Kl Q Rel = 0.619 | Kl Stddev Rel = [ 0.19552056 12.563247  ] | Loss Alpha = -0.006 | Loss Policy = 33.717 | Loss Temperature = 42.655 | Penalty Kl Q Rel = 0.404 | Pi Stddev Cond = 3.864 | Pi Stddev Max = 0.131 | Pi Stddev Min = 0.063 | Policy Loss = [33.71682] | Q Max = 43.348 | Q Min = 42.030 | Steps = 7684 | Walltime = 45.746\n",
            "I1206 21:31:59.386597 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.926 | Dual Alpha Mean = 14.002 | Dual Alpha Stddev = 42.233 | Dual Temperature = 1.161 | Kl Mean Rel = [0.18820997 0.52536356] | Kl Q Rel = 0.711 | Kl Stddev Rel = [1.2317879 5.3098125] | Loss Alpha = 0.017 | Loss Policy = 35.808 | Loss Temperature = 44.410 | Penalty Kl Q Rel = 0.354 | Pi Stddev Cond = 2.194 | Pi Stddev Max = 0.124 | Pi Stddev Min = 0.066 | Policy Loss = [35.80819] | Q Max = 44.972 | Q Min = 43.200 | Steps = 7856 | Walltime = 46.749\n",
            "I1206 21:31:59.496454 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 94.21163177490234 | Episodes = 94 | Steps = 7903 | Steps Per Second = 174.859\n",
            "I1206 21:32:00.388318 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.942 | Dual Alpha Mean = 14.103 | Dual Alpha Stddev = 42.890 | Dual Temperature = 1.286 | Kl Mean Rel = [0.03466344 0.18084095] | Kl Q Rel = 0.917 | Kl Stddev Rel = [0.06085975 0.1517892 ] | Loss Alpha = 0.025 | Loss Policy = 36.537 | Loss Temperature = 44.571 | Penalty Kl Q Rel = 1.713 | Pi Stddev Cond = 2.508 | Pi Stddev Max = 0.156 | Pi Stddev Min = 0.073 | Policy Loss = [36.537468] | Q Max = 45.269 | Q Min = 43.176 | Steps = 8022 | Walltime = 47.751\n",
            "I1206 21:32:00.711982 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 98.07466125488281 | Episodes = 96 | Steps = 8105 | Steps Per Second = 169.290\n",
            "I1206 21:32:01.389690 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.944 | Dual Alpha Mean = 14.288 | Dual Alpha Stddev = 43.448 | Dual Temperature = 1.027 | Kl Mean Rel = [0.27050805 0.37017667] | Kl Q Rel = 1.008 | Kl Stddev Rel = [2.2188897  0.48745954] | Loss Alpha = 0.019 | Loss Policy = 39.635 | Loss Temperature = 47.138 | Penalty Kl Q Rel = 1.870 | Pi Stddev Cond = 2.135 | Pi Stddev Max = 0.181 | Pi Stddev Min = 0.078 | Policy Loss = [39.63527] | Q Max = 47.756 | Q Min = 45.857 | Steps = 8190 | Walltime = 48.752\n",
            "I1206 21:32:01.884050 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 99.3945541381836 | Episodes = 98 | Steps = 8307 | Steps Per Second = 176.878\n",
            "I1206 21:32:02.389913 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.921 | Dual Alpha Mean = 14.819 | Dual Alpha Stddev = 44.171 | Dual Temperature = 1.165 | Kl Mean Rel = [0.45914608 0.70810664] | Kl Q Rel = 0.841 | Kl Stddev Rel = [ 7.417862  11.7513275] | Loss Alpha = 0.010 | Loss Policy = 38.104 | Loss Temperature = 46.012 | Penalty Kl Q Rel = 2.199 | Pi Stddev Cond = 2.378 | Pi Stddev Max = 0.162 | Pi Stddev Min = 0.077 | Policy Loss = [38.103703] | Q Max = 46.645 | Q Min = 45.057 | Steps = 8363 | Walltime = 49.753\n",
            "I1206 21:32:03.100821 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 99.5397720336914 | Episodes = 100 | Steps = 8509 | Steps Per Second = 165.896\n",
            "I1206 21:32:03.393819 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.886 | Dual Alpha Mean = 14.726 | Dual Alpha Stddev = 44.555 | Dual Temperature = 0.961 | Kl Mean Rel = [0.00892146 0.11728796] | Kl Q Rel = 1.284 | Kl Stddev Rel = [2.2247705 0.3619527] | Loss Alpha = 0.027 | Loss Policy = 38.999 | Loss Temperature = 46.577 | Penalty Kl Q Rel = 1.814 | Pi Stddev Cond = 2.344 | Pi Stddev Max = 0.163 | Pi Stddev Min = 0.078 | Policy Loss = [38.998787] | Q Max = 47.178 | Q Min = 45.544 | Steps = 8530 | Walltime = 50.757\n",
            "I1206 21:32:04.281479 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.3376235961914 | Episodes = 102 | Steps = 8711 | Steps Per Second = 173.797\n",
            "I1206 21:32:04.399428 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.973 | Dual Alpha Mean = 14.878 | Dual Alpha Stddev = 45.170 | Dual Temperature = 0.790 | Kl Mean Rel = [2.2818825  0.59563035] | Kl Q Rel = 1.270 | Kl Stddev Rel = [ 0.20665577 18.83617   ] | Loss Alpha = -0.005 | Loss Policy = 38.652 | Loss Temperature = 46.159 | Penalty Kl Q Rel = 0.948 | Pi Stddev Cond = 3.007 | Pi Stddev Max = 0.164 | Pi Stddev Min = 0.076 | Policy Loss = [38.652218] | Q Max = 46.711 | Q Min = 45.220 | Steps = 8702 | Walltime = 51.762\n",
            "I1206 21:32:05.399916 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.958 | Dual Alpha Mean = 14.902 | Dual Alpha Stddev = 45.530 | Dual Temperature = 0.727 | Kl Mean Rel = [1.8124994 0.8093813] | Kl Q Rel = 1.095 | Kl Stddev Rel = [ 0.12536378 29.507614  ] | Loss Alpha = -0.005 | Loss Policy = 37.756 | Loss Temperature = 45.986 | Penalty Kl Q Rel = 1.903 | Pi Stddev Cond = 2.743 | Pi Stddev Max = 0.161 | Pi Stddev Min = 0.076 | Policy Loss = [37.755756] | Q Max = 46.587 | Q Min = 45.019 | Steps = 8872 | Walltime = 52.763\n",
            "I1206 21:32:05.469662 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.81666564941406 | Episodes = 104 | Steps = 8913 | Steps Per Second = 171.669\n",
            "I1206 21:32:06.404599 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.889 | Dual Alpha Mean = 15.137 | Dual Alpha Stddev = 46.288 | Dual Temperature = 0.516 | Kl Mean Rel = [0.0150762 1.3797936] | Kl Q Rel = 0.681 | Kl Stddev Rel = [1.2591366 2.0249462] | Loss Alpha = 0.001 | Loss Policy = 42.815 | Loss Temperature = 51.294 | Penalty Kl Q Rel = 0.029 | Pi Stddev Cond = 1.485 | Pi Stddev Max = 0.095 | Pi Stddev Min = 0.076 | Policy Loss = [42.815193] | Q Max = 51.483 | Q Min = 50.722 | Steps = 9046 | Walltime = 53.767\n",
            "I1206 21:32:06.630590 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.80130767822266 | Episodes = 106 | Steps = 9115 | Steps Per Second = 175.870\n",
            "I1206 21:32:07.409413 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.864 | Dual Alpha Mean = 15.174 | Dual Alpha Stddev = 46.880 | Dual Temperature = 0.759 | Kl Mean Rel = [1.3696924 3.622928 ] | Kl Q Rel = 0.685 | Kl Stddev Rel = [18.158966   0.2608509] | Loss Alpha = -0.060 | Loss Policy = 36.912 | Loss Temperature = 45.836 | Penalty Kl Q Rel = 0.264 | Pi Stddev Cond = 3.463 | Pi Stddev Max = 0.116 | Pi Stddev Min = 0.066 | Policy Loss = [36.91151] | Q Max = 46.396 | Q Min = 45.355 | Steps = 9223 | Walltime = 54.772\n",
            "I1206 21:32:07.790795 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.67749786376953 | Episodes = 108 | Steps = 9317 | Steps Per Second = 172.412\n",
            "I1206 21:32:08.414186 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.885 | Dual Alpha Mean = 15.510 | Dual Alpha Stddev = 47.491 | Dual Temperature = 0.738 | Kl Mean Rel = [2.2059262 2.0711691] | Kl Q Rel = 0.482 | Kl Stddev Rel = [ 2.9364648 27.427837 ] | Loss Alpha = -0.036 | Loss Policy = 40.673 | Loss Temperature = 49.536 | Penalty Kl Q Rel = 0.058 | Pi Stddev Cond = 1.676 | Pi Stddev Max = 0.095 | Pi Stddev Min = 0.075 | Policy Loss = [40.67279] | Q Max = 49.831 | Q Min = 48.947 | Steps = 9396 | Walltime = 55.777\n",
            "I1206 21:32:08.972332 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.55977630615234 | Episodes = 110 | Steps = 9519 | Steps Per Second = 169.726\n",
            "I1206 21:32:09.417189 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.845 | Dual Alpha Mean = 15.458 | Dual Alpha Stddev = 48.206 | Dual Temperature = 0.689 | Kl Mean Rel = [5.4955854 1.0366424] | Kl Q Rel = 0.611 | Kl Stddev Rel = [2.7769317e-03 8.3275543e+01] | Loss Alpha = -0.045 | Loss Policy = 40.896 | Loss Temperature = 49.340 | Penalty Kl Q Rel = 0.004 | Pi Stddev Cond = 1.323 | Pi Stddev Max = 0.093 | Pi Stddev Min = 0.076 | Policy Loss = [40.89602] | Q Max = 49.613 | Q Min = 48.666 | Steps = 9564 | Walltime = 56.780\n",
            "I1206 21:32:10.158700 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.59058380126953 | Episodes = 112 | Steps = 9721 | Steps Per Second = 174.229\n",
            "I1206 21:32:10.425333 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.938 | Dual Alpha Mean = 15.807 | Dual Alpha Stddev = 49.459 | Dual Temperature = 0.609 | Kl Mean Rel = [0.50676626 1.2104831 ] | Kl Q Rel = 1.229 | Kl Stddev Rel = [14.912923 47.533752] | Loss Alpha = -0.004 | Loss Policy = 40.059 | Loss Temperature = 48.113 | Penalty Kl Q Rel = 1.659 | Pi Stddev Cond = 3.196 | Pi Stddev Max = 0.161 | Pi Stddev Min = 0.074 | Policy Loss = [40.059273] | Q Max = 48.530 | Q Min = 47.428 | Steps = 9735 | Walltime = 57.786\n",
            "I1206 21:32:11.384133 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.6865005493164 | Episodes = 114 | Steps = 9923 | Steps Per Second = 167.251\n",
            "I1206 21:32:11.428114 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.918 | Dual Alpha Mean = 15.697 | Dual Alpha Stddev = 50.384 | Dual Temperature = 0.497 | Kl Mean Rel = [0. 0.] | Kl Q Rel = 0.930 | Kl Stddev Rel = [0. 0.] | Loss Alpha = 0.031 | Loss Policy = 41.221 | Loss Temperature = 50.051 | Penalty Kl Q Rel = 0.242 | Pi Stddev Cond = 1.941 | Pi Stddev Max = 0.112 | Pi Stddev Min = 0.075 | Policy Loss = [41.220875] | Q Max = 50.337 | Q Min = 49.372 | Steps = 9901 | Walltime = 58.791\n",
            "I1206 21:32:12.429368 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.908 | Dual Alpha Mean = 15.398 | Dual Alpha Stddev = 50.906 | Dual Temperature = 0.580 | Kl Mean Rel = [ 0.11115455 25.291906  ] | Kl Q Rel = 0.422 | Kl Stddev Rel = [ 7.9529247 45.002266 ] | Loss Alpha = -0.563 | Loss Policy = 36.298 | Loss Temperature = 45.663 | Penalty Kl Q Rel = 0.451 | Pi Stddev Cond = 4.947 | Pi Stddev Max = 0.117 | Pi Stddev Min = 0.065 | Policy Loss = [36.297512] | Q Max = 46.102 | Q Min = 45.390 | Steps = 10070 | Walltime = 59.792\n",
            "I1206 21:32:12.574539 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.6937484741211 | Episodes = 116 | Steps = 10125 | Steps Per Second = 175.704\n",
            "I1206 21:32:13.434844 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.904 | Dual Alpha Mean = 15.454 | Dual Alpha Stddev = 51.542 | Dual Temperature = 0.689 | Kl Mean Rel = [0.660776  3.9107783] | Kl Q Rel = 0.821 | Kl Stddev Rel = [ 4.3878326 52.56384  ] | Loss Alpha = -0.070 | Loss Policy = 38.672 | Loss Temperature = 46.890 | Penalty Kl Q Rel = 1.707 | Pi Stddev Cond = 2.385 | Pi Stddev Max = 0.168 | Pi Stddev Min = 0.073 | Policy Loss = [38.671883] | Q Max = 47.383 | Q Min = 46.117 | Steps = 10243 | Walltime = 60.798\n",
            "I1206 21:32:13.748714 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.74537658691406 | Episodes = 118 | Steps = 10327 | Steps Per Second = 171.423\n",
            "I1206 21:32:14.438800 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.867 | Dual Alpha Mean = 15.927 | Dual Alpha Stddev = 52.597 | Dual Temperature = 0.718 | Kl Mean Rel = [3.283019   0.15917306] | Kl Q Rel = 0.850 | Kl Stddev Rel = [0.03294395 1.3976513 ] | Loss Alpha = 0.003 | Loss Policy = 40.714 | Loss Temperature = 49.514 | Penalty Kl Q Rel = 0.116 | Pi Stddev Cond = 2.767 | Pi Stddev Max = 0.103 | Pi Stddev Min = 0.072 | Policy Loss = [40.714447] | Q Max = 50.015 | Q Min = 48.792 | Steps = 10414 | Walltime = 61.802\n",
            "I1206 21:32:14.921409 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.76762390136719 | Episodes = 120 | Steps = 10529 | Steps Per Second = 177.791\n",
            "I1206 21:32:15.440730 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.848 | Dual Alpha Mean = 16.007 | Dual Alpha Stddev = 52.940 | Dual Temperature = 0.434 | Kl Mean Rel = [0.00806076 0.03085076] | Kl Q Rel = 1.325 | Kl Stddev Rel = [ 1.0010164 44.85346  ] | Loss Alpha = 0.029 | Loss Policy = 42.508 | Loss Temperature = 51.060 | Penalty Kl Q Rel = 0.032 | Pi Stddev Cond = 1.415 | Pi Stddev Max = 0.094 | Pi Stddev Min = 0.072 | Policy Loss = [42.50802] | Q Max = 51.395 | Q Min = 50.475 | Steps = 10589 | Walltime = 62.804\n",
            "I1206 21:32:16.118735 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.7972183227539 | Episodes = 122 | Steps = 10731 | Steps Per Second = 166.981\n",
            "I1206 21:32:16.443397 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.881 | Dual Alpha Mean = 16.439 | Dual Alpha Stddev = 53.527 | Dual Temperature = 0.495 | Kl Mean Rel = [1.8326968 2.0800679] | Kl Q Rel = 0.642 | Kl Stddev Rel = [ 3.0931375 10.617593 ] | Loss Alpha = -0.034 | Loss Policy = 40.308 | Loss Temperature = 49.163 | Penalty Kl Q Rel = 0.225 | Pi Stddev Cond = 1.976 | Pi Stddev Max = 0.102 | Pi Stddev Min = 0.068 | Policy Loss = [40.30821] | Q Max = 49.388 | Q Min = 48.647 | Steps = 10759 | Walltime = 63.806\n",
            "I1206 21:32:17.299943 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.55155944824219 | Episodes = 124 | Steps = 10933 | Steps Per Second = 168.446\n",
            "I1206 21:32:17.443403 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.836 | Dual Alpha Mean = 16.620 | Dual Alpha Stddev = 54.085 | Dual Temperature = 0.527 | Kl Mean Rel = [0.00527969 0.03815091] | Kl Q Rel = 0.479 | Kl Stddev Rel = [9.046202  0.5367332] | Loss Alpha = 0.032 | Loss Policy = 41.515 | Loss Temperature = 50.570 | Penalty Kl Q Rel = 0.127 | Pi Stddev Cond = 1.748 | Pi Stddev Max = 0.100 | Pi Stddev Min = 0.072 | Policy Loss = [41.515305] | Q Max = 50.791 | Q Min = 50.088 | Steps = 10929 | Walltime = 64.806\n",
            "I1206 21:32:18.444818 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.862 | Dual Alpha Mean = 16.995 | Dual Alpha Stddev = 54.754 | Dual Temperature = 0.423 | Kl Mean Rel = [0.02669876 0.20913269] | Kl Q Rel = 0.979 | Kl Stddev Rel = [0.27686474 1.4158916 ] | Loss Alpha = 0.028 | Loss Policy = 40.697 | Loss Temperature = 49.066 | Penalty Kl Q Rel = 0.661 | Pi Stddev Cond = 2.246 | Pi Stddev Max = 0.121 | Pi Stddev Min = 0.071 | Policy Loss = [40.696697] | Q Max = 49.394 | Q Min = 48.652 | Steps = 11094 | Walltime = 65.808\n",
            "I1206 21:32:18.517975 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.6981430053711 | Episodes = 126 | Steps = 11135 | Steps Per Second = 166.299\n",
            "I1206 21:32:19.445391 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.895 | Dual Alpha Mean = 17.447 | Dual Alpha Stddev = 55.815 | Dual Temperature = 0.520 | Kl Mean Rel = [ 2.3398247 14.120326 ] | Kl Q Rel = 1.618 | Kl Stddev Rel = [10.73144 10.11397] | Loss Alpha = -0.362 | Loss Policy = 39.317 | Loss Temperature = 47.071 | Penalty Kl Q Rel = 2.114 | Pi Stddev Cond = 3.387 | Pi Stddev Max = 0.192 | Pi Stddev Min = 0.074 | Policy Loss = [39.31686] | Q Max = 47.557 | Q Min = 46.003 | Steps = 11263 | Walltime = 66.808\n",
            "I1206 21:32:19.719214 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.81884765625 | Episodes = 128 | Steps = 11337 | Steps Per Second = 168.169\n",
            "I1206 21:32:20.445667 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.817 | Dual Alpha Mean = 17.886 | Dual Alpha Stddev = 56.467 | Dual Temperature = 0.548 | Kl Mean Rel = [0.29814243 0.18401392] | Kl Q Rel = 0.690 | Kl Stddev Rel = [6.368131 8.632615] | Loss Alpha = 0.027 | Loss Policy = 41.118 | Loss Temperature = 49.710 | Penalty Kl Q Rel = 0.095 | Pi Stddev Cond = 1.441 | Pi Stddev Max = 0.102 | Pi Stddev Min = 0.072 | Policy Loss = [41.117897] | Q Max = 49.950 | Q Min = 49.115 | Steps = 11426 | Walltime = 67.808\n",
            "I1206 21:32:20.950946 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.18421173095703 | Episodes = 130 | Steps = 11539 | Steps Per Second = 166.649\n",
            "I1206 21:32:21.448154 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.857 | Dual Alpha Mean = 18.372 | Dual Alpha Stddev = 57.317 | Dual Temperature = 0.811 | Kl Mean Rel = [0.48028725 5.5695596 ] | Kl Q Rel = 0.521 | Kl Stddev Rel = [ 2.6229343 14.746981 ] | Loss Alpha = -0.124 | Loss Policy = 41.292 | Loss Temperature = 50.132 | Penalty Kl Q Rel = 0.021 | Pi Stddev Cond = 1.384 | Pi Stddev Max = 0.095 | Pi Stddev Min = 0.072 | Policy Loss = [41.292175] | Q Max = 50.444 | Q Min = 49.470 | Steps = 11590 | Walltime = 68.811\n",
            "I1206 21:32:22.181544 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.05313873291016 | Episodes = 132 | Steps = 11741 | Steps Per Second = 165.799\n",
            "I1206 21:32:22.452298 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.880 | Dual Alpha Mean = 18.686 | Dual Alpha Stddev = 57.974 | Dual Temperature = 0.603 | Kl Mean Rel = [0.29376158 0.19188438] | Kl Q Rel = 0.310 | Kl Stddev Rel = [ 0.24379225 11.844266  ] | Loss Alpha = 0.029 | Loss Policy = 42.209 | Loss Temperature = 51.410 | Penalty Kl Q Rel = 0.196 | Pi Stddev Cond = 2.011 | Pi Stddev Max = 0.099 | Pi Stddev Min = 0.070 | Policy Loss = [42.20869] | Q Max = 51.640 | Q Min = 51.033 | Steps = 11757 | Walltime = 69.815\n",
            "I1206 21:32:23.396611 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.32564544677734 | Episodes = 134 | Steps = 11943 | Steps Per Second = 166.586\n",
            "I1206 21:32:23.457683 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.877 | Dual Alpha Mean = 18.586 | Dual Alpha Stddev = 58.590 | Dual Temperature = 0.435 | Kl Mean Rel = [6.043398   0.18967538] | Kl Q Rel = 1.443 | Kl Stddev Rel = [0.8823476 0.5232272] | Loss Alpha = -0.021 | Loss Policy = 41.180 | Loss Temperature = 49.382 | Penalty Kl Q Rel = 1.963 | Pi Stddev Cond = 2.650 | Pi Stddev Max = 0.142 | Pi Stddev Min = 0.071 | Policy Loss = [41.179688] | Q Max = 49.844 | Q Min = 48.629 | Steps = 11924 | Walltime = 70.820\n",
            "I1206 21:32:24.457781 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.862 | Dual Alpha Mean = 18.769 | Dual Alpha Stddev = 59.212 | Dual Temperature = 0.479 | Kl Mean Rel = [5.7308135 2.7632902] | Kl Q Rel = 1.277 | Kl Stddev Rel = [ 3.4892428 10.247347 ] | Loss Alpha = -0.093 | Loss Policy = 40.332 | Loss Temperature = 48.696 | Penalty Kl Q Rel = 2.064 | Pi Stddev Cond = 3.146 | Pi Stddev Max = 0.152 | Pi Stddev Min = 0.072 | Policy Loss = [40.33194] | Q Max = 49.109 | Q Min = 48.015 | Steps = 12095 | Walltime = 71.821\n",
            "I1206 21:32:24.585662 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.82551574707031 | Episodes = 136 | Steps = 12145 | Steps Per Second = 166.280\n",
            "I1206 21:32:25.457989 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.869 | Dual Alpha Mean = 19.619 | Dual Alpha Stddev = 60.311 | Dual Temperature = 0.494 | Kl Mean Rel = [ 0.55976284 16.202198  ] | Kl Q Rel = 1.065 | Kl Stddev Rel = [ 2.9820833 14.903005 ] | Loss Alpha = -0.449 | Loss Policy = 41.534 | Loss Temperature = 50.404 | Penalty Kl Q Rel = 0.337 | Pi Stddev Cond = 3.689 | Pi Stddev Max = 0.110 | Pi Stddev Min = 0.069 | Policy Loss = [41.53364] | Q Max = 50.776 | Q Min = 49.896 | Steps = 12260 | Walltime = 72.821\n",
            "I1206 21:32:25.796613 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.66947174072266 | Episodes = 138 | Steps = 12347 | Steps Per Second = 170.697\n",
            "I1206 21:32:26.460803 140093364000640 terminal.py:91] [Learner] Critic Loss = 2.877 | Dual Alpha Mean = 20.139 | Dual Alpha Stddev = 61.555 | Dual Temperature = 0.575 | Kl Mean Rel = [1.9605393  0.45150414] | Kl Q Rel = 0.659 | Kl Stddev Rel = [31.815496 20.024176] | Loss Alpha = 0.004 | Loss Policy = 39.835 | Loss Temperature = 48.863 | Penalty Kl Q Rel = 0.489 | Pi Stddev Cond = 3.645 | Pi Stddev Max = 0.107 | Pi Stddev Min = 0.068 | Policy Loss = [39.834732] | Q Max = 49.279 | Q Min = 48.505 | Steps = 12430 | Walltime = 73.824\n",
            "I1206 21:32:27.007184 140093364000640 terminal.py:91] [Environment Loop] Episode Length = 101 | Episode Return = 100.74944305419922 | Episodes = 140 | Steps = 12549 | Steps Per Second = 165.921\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:561: UserWarning: Encoding a StructuredValue with type tfp.distributions.MultivariateNormalDiag_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
            "  \"imported and registered.\" % type_spec_class_name)\n",
            "INFO:tensorflow:Assets written to: /root/acme/cd0f6372-56db-11ec-a77c-0242ac1c0002/snapshots/policy/assets\n",
            "I1206 21:32:27.106665 140093364000640 builder_impl.py:784] Assets written to: /root/acme/cd0f6372-56db-11ec-a77c-0242ac1c0002/snapshots/policy/assets\n",
            "[reverb/cc/platform/default/server.cc:84] Shutting down replay server\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5sL3pj1qCpJ",
        "outputId": "f81bb7cc-c05e-4fa9-c86f-4934434a703c"
      },
      "source": [
        "cd /root/acme"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/acme\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glODweODqgVv",
        "outputId": "0217cc84-48eb-42eb-cea3-b765f33412da"
      },
      "source": [
        "ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcd0f6372-56db-11ec-a77c-0242ac1c0002\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6WQf6FO8qg_l",
        "outputId": "764b66af-8cda-4e60-875d-90ce5d4a7114"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/acme'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJz6hbITqiDe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}